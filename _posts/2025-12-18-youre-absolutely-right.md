---
layout: post
title:  "You're absolutely right"
date:   2025-12-18
last_modified_at: 2025-12-18
categories: [AI]
pinned: true
---

Thank you, ChatGPT, for acknowledging the fact that you've deliberately given me the wrong answer for the 4th time in a row. Technically, I'd be wrong to say 'deliberately', as it doesn't _know_ that it's wrong; it only seems this way because LLMs are yes-men.<br>

A sycophant is <a href="https://www.merriam-webster.com/dictionary/sycophant" target="_blank">one who praises those in power in order to gain their approval</a>. LLMs are trained via reinforcement learning from human feedback (RLHF), which as you could infer, uses human feedback to create a reward model that guides the AI's behavior. RLHF is really effective for open-ended tasks like creative writing, because it essentially teaches AI subjectivity and teaches models to align themselves with human values. This is where LLMs learn to "read the room" to produce an appropriate response in whatever context it finds itself in, in an attempt to maximize its internal score to be rewarded.<br>

So no, ChatGPT isn't the rage-baiting, spineless, good-for-nothing robot everyone except me makes it out to be when they give it a prompt that isn't just asking how to center a div. It has learned that telling us that we're absolutely right all the time is polite and helpful, two things us humans value. Even at the expense of <s>~~my~~</s> everyone else's happiness and sanity, two other things us humans value.<br>

I was inspired to dig deeper into this behavior and write about this after watching <a href="https://www.youtube.com/watch?v=rmvDxxNubIg" target="_blank">Dex Horthy's No Vibes Allowed talk at Code Summit</a>.
